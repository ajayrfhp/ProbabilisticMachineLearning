{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why Jax ?\n",
    "  - Automatically differentiate native python and numpy code to run on CPU, GPU and TPU \n",
    "  - Jax uses XLA to compile and run numpy code on hardware acclerators.\n",
    "    - jax also allows you to just in time compile your python functions into XLA optimized kernels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random, device_put\n",
    "import numpy as onp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.372111    0.2642311  -0.18252774 -0.7368198  -0.44030386 -0.15214427\n",
      " -0.6713536  -0.59086424  0.73168874  0.56730247]\n"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(0)\n",
    "x = random.normal(key, (10,))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 ms ± 3.43 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "size = 3000\n",
    "x = random.normal(key, (size, size), dtype=jnp.float32)\n",
    "%timeit jnp.dot(x, x.T).block_until_ready()  # runs on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 ms ± 1.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "ox = onp.random.random((size, size))\n",
    "%timeit onp.dot(x, x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What in devil's name is this thing. How is it 10 times faster than numpy ?\n",
    "  - Jax can run on GPU and is this 10 times faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jax works on regular numpy arrays\n",
    "  - but this is slower because jax has to copy numpy array into gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.7 ms ± 878 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = onp.random.normal(size=(size, size)).astype(onp.float32)\n",
    "%timeit jnp.dot(x, x.T).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.9 ms ± 178 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = device_put(x)\n",
    "%timeit jnp.dot(x, x.T).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- JAX is more than a GPU backend for numpy\n",
    "  - jit(), for speeding up your code\n",
    "    - JIT allows fast execution by converting intermediate code to native code and stores native code. \n",
    "    - JIT compiler runs with execution of program\n",
    "  - grad(), for taking derivatives\n",
    "  - vmap(), for automatic vectorization or batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.77 ms ± 50.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "  return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "x = random.normal(key, (1000000,))\n",
    "%timeit selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 µs ± 18.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "selu_jit = jit(selu)\n",
    "%timeit selu_jit(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25       0.19661197 0.10499357]\n"
     ]
    }
   ],
   "source": [
    "def sum_logistic(x):\n",
    "  return jnp.sum(1.0 / (1.0 + jnp.exp(-x)))\n",
    "\n",
    "x_small = jnp.arange(3.)\n",
    "derivative_fn = grad(sum_logistic)\n",
    "print(derivative_fn(x_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DeviceArray([0.24998187, 0.1964569 , 0.10502338], dtype=float32)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first_finite_differences(f, x):\n",
    "  eps = 1e-3\n",
    "  return jnp.array([(f(x + eps * v) - f(x - eps * v)) / (2 * eps)\n",
    "                   for v in jnp.eye(len(x))])\n",
    "\n",
    "first_finite_differences(sum_logistic, x_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = random.normal(key, (5000, 1000))\n",
    "v = random.normal(key, (10, 1000))\n",
    "\n",
    "@jit\n",
    "def apply_matrix(v):\n",
    "    return jnp.dot(v, mat.T)\n",
    "\n",
    "def naive_apply_matrix(v):\n",
    "    return jnp.stack([apply_matrix(r) for r in v])\n",
    "\n",
    "@jit\n",
    "def vmap_apply_matrix(v):\n",
    "    return vmap(apply_matrix)(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582 µs ± 8.55 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit apply_matrix(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.38 ms ± 89.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit naive_apply_matrix(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602 µs ± 183 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit vmap_apply_matrix(v).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running on GPU, Jit and Vmap really speeds things up\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd019b34c45716214053d0f793ec4110e5aec262f5624fd852d380a9a4bfce47f75"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "19b34c45716214053d0f793ec4110e5aec262f5624fd852d380a9a4bfce47f75"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}